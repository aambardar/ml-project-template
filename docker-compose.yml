# Docker Compose for ML Development
# ==================================
# Usage:
#   docker compose up -d                            # Start container in background
#   docker compose exec oneringtorulethemall bash   # Open shell in container
#   docker compose down                             # Stop container

services:
  oneringtorulethemall:
    build:
      context: .
      dockerfile: docker/Dockerfile
    image: ml-base:latest
    container_name: ml-one

    # Mount project directory for live code changes
    # [HOST PATH] : [CONTAINER PATH]
    # Mount the left side On the right side location.
    volumes:
      # Project code - synced via PyCharm
      - ${DOCKER_VM_PROJECT_BASE_PATH:-.}/${PROJECT_NAME:-ml-default}:/app

      # Data - large files, NOT synced (stays on VM)
      - ${DOCKER_VM_DATA_BASE_PATH:-./data}/${PROJECT_NAME:-ml-default}:/data
      # Models - trained model artifacts
      - ${DOCKER_VM_MODELS_BASE_PATH:-./models}/${PROJECT_NAME:-ml-default}:/models

      # Outputs - logs, figures, checkpoints
      - ${DOCKER_VM_OUTPUTS_BASE_PATH:-./outputs}/${PROJECT_NAME:-ml-default}:/outputs

      # Jupyter settings persistence
      - jupyter-data:/root/.jupyter

    # Expose common ML service ports
    ports:
      - "${JUPYTER_PORT:-8888}:${JUPYTER_PORT:-8888}"           # JupyterLab
      - "${API_PORT:-8000}:${API_PORT:-8000}"                   # FastAPI / Model serving
      - "${MLFLOW_PORT:-5000}:${MLFLOW_PORT:-5000}"             # MLflow
      - "${TENSORBOARD_PORT:-6006}:${TENSORBOARD_PORT:-6006}"   # TensorBoard

    # Keep container running for interactive use
    stdin_open: true
    tty: true

    # Restart policy
    restart: unless-stopped

    # Working directory
    working_dir: /app

volumes:
  jupyter-data:
